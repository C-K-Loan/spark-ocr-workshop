{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of parsing FoundationOne report using Spark OCR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install spark-ocr python packge\n",
    "Need specify path to `spark-ocr-assembly-[version].jar` or `secret`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "secret = \"\"\n",
    "license = \"\"\n",
    "version = secret.split(\"-\")[0]\n",
    "spark_ocr_jar_path = \"../../target/scala-2.11\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "if python -c 'import google.colab' &> /dev/null; then\n",
    "    echo \"Run on Google Colab!\"\n",
    "    echo \"Install Open JDK\"\n",
    "    apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
    "    java -version\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "if 'google.colab' in sys.modules:\n",
    "  os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "  os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install from PYPI using secret\n",
    "%pip install spark-ocr==$version --user --extra-index-url=https://pypi.johnsnowlabs.com/$secret --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /Users/nmelnik/IdeaProjects/spark-ocr/python/dist/spark-ocr-1.5.0rc1.tar.gz\n",
      "Requirement already satisfied: numpy==1.17.4 in /Users/nmelnik/Library/Python/3.7/lib/python/site-packages (from spark-ocr==1.5.0rc1) (1.17.4)\n",
      "Requirement already satisfied: pillow==6.2.1 in /Users/nmelnik/Library/Python/3.7/lib/python/site-packages (from spark-ocr==1.5.0rc1) (6.2.1)\n",
      "Requirement already satisfied: py4j==0.10.7 in /Users/nmelnik/Library/Python/3.7/lib/python/site-packages (from spark-ocr==1.5.0rc1) (0.10.7)\n",
      "Requirement already satisfied: pyspark==2.4.4 in /Users/nmelnik/Library/Python/3.7/lib/python/site-packages (from spark-ocr==1.5.0rc1) (2.4.4)\n",
      "Requirement already satisfied: python-levenshtein==0.12.0 in /Users/nmelnik/Library/Python/3.7/lib/python/site-packages (from spark-ocr==1.5.0rc1) (0.12.0)\n",
      "Requirement already satisfied: scikit-image==0.16.2 in /Users/nmelnik/Library/Python/3.7/lib/python/site-packages (from spark-ocr==1.5.0rc1) (0.16.2)\n",
      "Requirement already satisfied: implicits==1.0.2 in /Users/nmelnik/Library/Python/3.7/lib/python/site-packages (from spark-ocr==1.5.0rc1) (1.0.2)\n",
      "Requirement already satisfied: setuptools in /Users/nmelnik/Library/Python/3.7/lib/python/site-packages (from python-levenshtein==0.12.0->spark-ocr==1.5.0rc1) (46.0.0)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /Users/nmelnik/Library/Python/3.7/lib/python/site-packages (from scikit-image==0.16.2->spark-ocr==1.5.0rc1) (3.2.0)\n",
      "Requirement already satisfied: scipy>=0.19.0 in /Users/nmelnik/Library/Python/3.7/lib/python/site-packages (from scikit-image==0.16.2->spark-ocr==1.5.0rc1) (1.4.1)\n",
      "Requirement already satisfied: networkx>=2.0 in /Users/nmelnik/Library/Python/3.7/lib/python/site-packages (from scikit-image==0.16.2->spark-ocr==1.5.0rc1) (2.4)\n",
      "Requirement already satisfied: imageio>=2.3.0 in /Users/nmelnik/Library/Python/3.7/lib/python/site-packages (from scikit-image==0.16.2->spark-ocr==1.5.0rc1) (2.8.0)\n",
      "Requirement already satisfied: PyWavelets>=0.4.0 in /Users/nmelnik/Library/Python/3.7/lib/python/site-packages (from scikit-image==0.16.2->spark-ocr==1.5.0rc1) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/nmelnik/Library/Python/3.7/lib/python/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.16.2->spark-ocr==1.5.0rc1) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /Users/nmelnik/Library/Python/3.7/lib/python/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.16.2->spark-ocr==1.5.0rc1) (2.4.6)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/nmelnik/Library/Python/3.7/lib/python/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.16.2->spark-ocr==1.5.0rc1) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /Users/nmelnik/Library/Python/3.7/lib/python/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.16.2->spark-ocr==1.5.0rc1) (2.8.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /Users/nmelnik/Library/Python/3.7/lib/python/site-packages (from networkx>=2.0->scikit-image==0.16.2->spark-ocr==1.5.0rc1) (4.4.2)\n",
      "Requirement already satisfied: six in /Users/nmelnik/Library/Python/3.7/lib/python/site-packages (from cycler>=0.10->matplotlib!=3.0.0,>=2.0.0->scikit-image==0.16.2->spark-ocr==1.5.0rc1) (1.14.0)\n",
      "Building wheels for collected packages: spark-ocr\n",
      "  Building wheel for spark-ocr (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for spark-ocr: filename=spark_ocr-1.5.0rc1-cp37-none-any.whl size=7213975 sha256=0d5ef376d7f12106e0c10b48f803c676fe8376d24c052377a678ccbac8120d87\n",
      "  Stored in directory: /Users/nmelnik/Library/Caches/pip/wheels/0c/71/82/354c1ee65aba44577b5de7a59b21b1726d406bbcac419356c1\n",
      "Successfully built spark-ocr\n",
      "Installing collected packages: spark-ocr\n",
      "  Found existing installation: spark-ocr 1.4.0rc1\n",
      "    Uninstalling spark-ocr-1.4.0rc1:\n",
      "      Successfully uninstalled spark-ocr-1.4.0rc1\n",
      "Successfully installed spark-ocr-1.5.0rc1\n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 20.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# or install from local path\n",
    "%pip install --user ../../python/dist/spark-ocr-1.5.0rc1.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization of spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkConf Configured, Starting to listen on port: 64338\n",
      "JAR PATH:/usr/local/lib/python3.7/site-packages/sparkmonitor/listener.jar\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://melnyks-mbp.dlink:4042\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Spark OCR</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x114826250>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from sparkocr import start\n",
    "\n",
    "if license:\n",
    "    os.environ['JSL_OCR_LICENSE'] = license\n",
    "\n",
    "spark = start(secret=secret, jar_path=spark_ocr_jar_path)\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import OCR transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparkocr.transformers import *\n",
    "from sparkocr.enums import *\n",
    "from pyspark.ml import PipelineModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define OCR transformers and pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline():\n",
    "    \n",
    "    # Transforrm PDF document to images per page\n",
    "    pdf_to_text = PdfToText()\n",
    "    pdf_to_text.setOutputCol(\"text\")\n",
    "    pdf_to_text.setSplitPage(False)\n",
    "    pdf_to_text.setTextStripper(TextStripperType.PDF_LAYOUT_TEXT_STRIPPER)\n",
    "\n",
    "    genomic_parser = FoundationOneReportParser()\n",
    "    genomic_parser.setInputCol(\"text\")\n",
    "    genomic_parser.setOutputCol(\"genomics\")\n",
    "\n",
    "    \n",
    "    pipeline = PipelineModel(stages=[\n",
    "        pdf_to_text,\n",
    "        genomic_parser\n",
    "    ])\n",
    "    \n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read PDF document as binary file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pkg_resources\n",
    "pdf_example = pkg_resources.resource_filename('sparkocr', 'resources/ocr/pdfs/genomics/3.pdf')\n",
    "pdf_example_df = spark.read.format(\"binaryFile\").load(pdf_example).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run OCR pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pipeline().transform(pdf_example_df).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Biomarker_findings\" : [ {\n",
      "    \"name\" : \"Tumor Mutation Burden\",\n",
      "    \"state\" : \"TMB-Low (5Muts/Mb)\",\n",
      "    \"actionability\" : \"No therapies or clinical trials. \"\n",
      "  }, {\n",
      "    \"name\" : \"Microsatellite status\",\n",
      "    \"state\" : \"MS-Stable\",\n",
      "    \"actionability\" : \"No therapies or clinical trials. \"\n",
      "  } ],\n",
      "  \"Genomic_findings\" : [ {\n",
      "    \"name\" : \"MET\",\n",
      "    \"state\" : \"T263M\",\n",
      "    \"therapies_with_clinical_benefit_in_patient_tumor_type\" : [ \"Crizotinib\" ],\n",
      "    \"therapies_with_clinical_benefit_in_other_tumor_type\" : [ \"Cabozantinib\" ]\n",
      "  }, {\n",
      "    \"name\" : \"ERBB3\",\n",
      "    \"state\" : \"P1212S\",\n",
      "    \"therapies_with_clinical_benefit_in_patient_tumor_type\" : [ \"Afatinib\" ],\n",
      "    \"therapies_with_clinical_benefit_in_other_tumor_type\" : [ \"Trastuzumab-dkst\", \"Trastuzumab\", \"Pertuzumab\", \"Lapatinib\", \"Ado-trastuzumab emtansine\" ]\n",
      "  }, {\n",
      "    \"name\" : \"EGFR\",\n",
      "    \"state\" : \"amplification, exon 19 deletion\",\n",
      "    \"therapies_with_clinical_benefit_in_patient_tumor_type\" : [ \"Osimertinib\", \"Gefitinib\", \"Erlotinib\", \"Afatinib\" ],\n",
      "    \"therapies_with_clinical_benefit_in_other_tumor_type\" : [ \"Panitumumab\", \"Lapatinib\", \"Cetuximab\" ]\n",
      "  } ],\n",
      "  \"Patient\" : {\n",
      "    \"disease\" : \"Lung adenocarcinoma\",\n",
      "    \"name\" : null,\n",
      "    \"date_of_birth\" : null,\n",
      "    \"sex\" : null,\n",
      "    \"medical_record\" : null\n",
      "  },\n",
      "  \"Physician\" : {\n",
      "    \"ordering_physician\" : null,\n",
      "    \"medical_facility\" : null,\n",
      "    \"additional_recipient\" : null,\n",
      "    \"medical_facility_id\" : null,\n",
      "    \"pathologist\" : null\n",
      "  },\n",
      "  \"Specimen\" : {\n",
      "    \"specimen_site\" : null,\n",
      "    \"specimen_id\" : null,\n",
      "    \"specimen_type\" : null,\n",
      "    \"date_of_collection\" : null,\n",
      "    \"specimen_received\" : null\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(result.select(\"genomics\").collect()[0].genomics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clear cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[path: string, modificationTime: timestamp, length: bigint, image: struct<origin:string,height:int,width:int,nChannels:int,mode:int,resolution:int,data:binary>, pagenum: int, confidence: double, positions: array<struct<mapping:array<struct<c:string,p:int,x:float,y:float,width:float,height:float,fontSize:int>>>>, exception: string, text: string]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.unpersist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
